{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "SMALL_SIZE, MEDIUM_SIZE = 9, 12\n",
    "PROJECT_PATH = \"/Users/donghur/Desktop/Research/Murthy/BM_GPU\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import random, matplotlib\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sys.path.append(PROJECT_PATH)\n",
    "from utils.data import Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import utils.figure as ufigure\n",
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "%aimport utils.data\n",
    "%aimport utils.figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading INFO.yaml ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 4/141 [00:00<00:03, 35.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished loading INFO\n",
      "Loading config.yaml ...\n",
      "Finished loading config\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 140/141 [00:10<00:00, 13.95it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 1654768 into shape (12,10,15257)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-111-429e8286d4ab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mData\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPROJECT_PATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'final'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mData\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Desktop/Research/Murthy/BM_GPU/utils/data.py\u001b[0m in \u001b[0;36mload_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     39\u001b[0m                 \u001b[0mabs_data_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"{self.project_path}/{file['directory']}/{file_name}.npy\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mabs_data_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_obj\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mabs_data_path\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mfile_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_name\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_obj\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    438\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m                 return format.read_array(fid, allow_pickle=allow_pickle,\n\u001b[0;32m--> 440\u001b[0;31m                                          pickle_kwargs=pickle_kwargs)\n\u001b[0m\u001b[1;32m    441\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m             \u001b[0;31m# Try a pickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/numpy/lib/format.py\u001b[0m in \u001b[0;36mread_array\u001b[0;34m(fp, allow_pickle, pickle_kwargs)\u001b[0m\n\u001b[1;32m    766\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfortran_order\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 768\u001b[0;31m             \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    769\u001b[0m             \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    770\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 1654768 into shape (12,10,15257)"
     ]
    }
   ],
   "source": [
    "Data = Dataset(PROJECT_PATH, 'final')\n",
    "Data.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configuration\n",
    "INFO = Data.info\n",
    "INFO_values = Data.info_values\n",
    "config = Data.config\n",
    "skeleton = config['skeleton']\n",
    "skeleton_color= config['skeleton_color']\n",
    "\n",
    "# features\n",
    "bp = Data.data_obj['bodypoints']\n",
    "rot_bp = Data.data_obj['rotated_bodypoints']\n",
    "angles = Data.data_obj['angles']\n",
    "limbs = Data.data_obj['limbs']\n",
    "angle_power = Data.data_obj['angle_power']\n",
    "limb_power = Data.data_obj['limb_power']\n",
    "\n",
    "# embeddings\n",
    "all_embed = Data.data_obj['all_embeddings']\n",
    "all_postural_embed = Data.data_obj['all_postural_embeddings']\n",
    "all_kinematic_embed = Data.data_obj['all_kinematic_embeddings']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr><hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f848a2844b904f44a3a94799cd49611e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=141.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "INFO_items = list(INFO.items())\n",
    "INFO_items.sort(key=lambda x: x[1]['order'])\n",
    "tot_limb= []\n",
    "\n",
    "for key, file in tqdm(INFO_items):\n",
    "    save_path = file['directory']\n",
    "    bp = np.load(f\"{PROJECT_PATH}/{save_path}/rotated_bodypoints.npy\")\n",
    "    bp = bp.astype(\"float64\")\n",
    "    num_fr, num_bp, _ = bp.shape\n",
    "    likelihood = bp[:,:,2]\n",
    "    \n",
    "    ### Locate Bad Frames ###\n",
    "    # check if below likelihood threshold\n",
    "    (below_thresh_fr, below_thresh_marker) = np.where(likelihood < config['likelihood_thresh'])\n",
    "    cnt = collections.Counter(below_thresh_fr)\n",
    "    cnt_array = np.array(list(cnt.items()))\n",
    "    # check if above marker threshold\n",
    "    try:\n",
    "        # set low likelihood fr as bad fr\n",
    "        bad_fr_idx = np.where(cnt_array[:,1] > config['marker_thresh'])[0]\n",
    "        bad_fr = cnt_array[bad_fr_idx,0]\n",
    "        # set nan fr as bad fr\n",
    "        nan_fr, _, _ = np.where( np.isnan(bp) )\n",
    "        unique_nan_fr = np.unique(nan_fr)\n",
    "        bad_fr = np.concatenate([bad_fr, unique_nan_fr])\n",
    "        bad_fr = np.unique(bad_fr)\n",
    "        # append pads\n",
    "        padded_fr = np.array([ list(range(fr-config['bad_fr_pad'], fr+config['bad_fr_pad']+1)) for fr in bad_fr])\n",
    "        disregard_fr = np.unique(padded_fr.flatten())\n",
    "        disregard_fr = disregard_fr[(disregard_fr >= 0) & (disregard_fr < num_fr)]\n",
    "        good_fr_idx = np.array([True]*num_fr)\n",
    "        good_fr_idx[disregard_fr] = False\n",
    "        good_fr = np.where(good_fr_idx==True)[0]\n",
    "    except:\n",
    "        bad_fr = np.array([])\n",
    "        disregard_fr = np.array([])\n",
    "        good_fr = np.arange(num_fr)\n",
    "\n",
    "    # TODO: modify proportion of good fr\n",
    "    file['good_fr'] = good_fr.tolist()\n",
    "    file['bad_fr'] = bad_fr.tolist()\n",
    "    file['disregard_fr'] = disregard_fr.tolist()\n",
    "    \n",
    "    \n",
    "    # ********* fix ***********\n",
    "    limbs = np.zeros((num_fr, len(config['limbs'])))\n",
    "    for i, limb_pts in enumerate(config['limbs']):\n",
    "        bp_good_fr = bp[good_fr,:,:]\n",
    "\n",
    "        limb_i = bp_good_fr[:,limb_pts,:]\n",
    "        \n",
    "        limbs[good_fr,i] = np.sqrt((limb_i[:,0,0]-limb_i[:,1,0])**2 + (limb_i[:,0,1]-limb_i[:,1,1])**2)\n",
    "    inf_fr,_ = np.where(np.isinf(limbs))\n",
    "    if len(inf_fr) != 0:\n",
    "        break\n",
    "\n",
    "        \n",
    "#     tot_limb.append(limbs[good_fr,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4022.0"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_fr,_,_ = rot_bp.shape\n",
    "\n",
    "nan_fr,_,_ = np.where(np.isnan(rot_bp))\n",
    "nan_fr = np.unique(nan_fr)\n",
    "good_fr = np.array([True]*num_fr)\n",
    "good_fr[nan_fr] = False\n",
    "\n",
    "np.max(bp[good_fr,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "notebook_analysis",
   "language": "python",
   "name": "notebook_analysis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
